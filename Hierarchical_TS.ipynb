{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# X = pd.read_csv('./task_1_sample_submission.csv')\n",
    "# rows=10000\n",
    "# X['Channel'] = np.random.choice(a=[0, 1, 2], size=rows, p=[0.25, 0.50, 0.25])\n",
    "\n",
    "# X.to_csv('./task_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "import hts\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# settings\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams[\"figure.figsize\"] = (16, 8)\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./HCP_Data_KDAG_Hackathon/HCP_Data_KDAG_Hackathon.xlsx', parse_dates=['Time_Period'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Speaker_Programs_Attended', 'Vouchers_Dropped'], axis=1)\n",
    "df = df[['Physician_ID', 'Time_Period', 'Physician_Segment', 'Specialty', 'Sales_Rep_Calls', 'Samples_Dropped', 'Emails_Delivered', 'Brand_Rx', 'Market_Rx']]\n",
    "# df['Percent_Market_Share'] = df['Brand_Rx'] / df['Market_Rx'] * 100.0\n",
    "df['Specialty'] = df['Specialty'].map({'Dermatologist':'D', 'General Physician':'GP', 'Nurse Practitioner':'NP'})\n",
    "df['Physician_Segment'] = df['Physician_Segment'].map({'3-Low':'L', '2-Medium':'M', '1-High':'H'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = {'Sales_Rep_Calls':0, 'Samples_Dropped':1, 'Emails_Delivered':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of weeks when Sales_Rep_Calls, Samples_Dropped, Emails_Delivered are all 0\n",
    "df[['Sales_Rep_Calls', 'Samples_Dropped', 'Emails_Delivered']].apply(lambda x: (x!=0).sum(), axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the bottom level id\n",
    "df[\"seg_specialty_id\"] = df.apply(lambda x: f\"{x['Physician_Segment']}_{x['Specialty']}_{x['Physician_ID']}\", axis=1)\n",
    "# create the l1 level id\n",
    "df[\"seg_specialty\"] = df.apply(lambda x: f\"{x['Physician_Segment']}_{x['Specialty']}\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the bottom level df\n",
    "df_bottom_level = df.pivot(index=\"Time_Period\", columns=\"seg_specialty_id\", values=\"Brand_Rx\")\n",
    "df_bottom_level.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the l1 level df\n",
    "df_l1_level = df.groupby([\"Time_Period\", \"Physician_Segment\", \"Specialty\", \"seg_specialty\"]).sum() \\\n",
    "                    .reset_index(drop=False) \\\n",
    "                    .pivot(index=\"Time_Period\", columns=\"seg_specialty\", values=\"Brand_Rx\")\n",
    "df_l1_level.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the l2 level df\n",
    "df_l2_level = df.groupby([\"Time_Period\", \"Physician_Segment\"]).sum() \\\n",
    "                    .reset_index(drop=False) \\\n",
    "                    .pivot(index=\"Time_Period\", columns=\"Physician_Segment\", values=\"Brand_Rx\")\n",
    "df_l2_level.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the total level df\n",
    "df_total = df.groupby([\"Time_Period\"])[\"Brand_Rx\"].sum() \\\n",
    "                    .to_frame().rename(columns={\"Brand_Rx\": \"total\"})\n",
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the DataFrames\n",
    "hierarchy_df = df_bottom_level.join(df_l1_level).join(df_l2_level).join(df_total)\n",
    "hierarchy_df.index = pd.to_datetime(hierarchy_df.index)\n",
    "hierarchy_df = hierarchy_df.resample('W-FRI').sum()\n",
    "\n",
    "hierarchy_df.head(100)\n",
    "# if(hierarchy_df1 == hierarchy_df).all().all():\n",
    "#     print(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = df[\"Physician_Segment\"].unique()\n",
    "specialties = df[\"seg_specialty\"].unique()\n",
    "ids = df[\"seg_specialty_id\"].unique()\n",
    "\n",
    "total = {'total': list(segments)}\n",
    "segment = {k: [v for v in specialties if v.startswith(k)] for k in segments}\n",
    "id = {k: [v for v in ids if v.startswith(k)] for k in specialties}\n",
    "hierarchy = {**total, **segment, **id}\n",
    "\n",
    "hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ols_prophet = hts.HTSRegressor(model='prophet', revision_method='OLS', n_jobs=0)\n",
    "# model_ols_prophet = model_ols_prophet.fit(hierarchy_df, hierarchy)\n",
    "# with open('model_ols_prophet.pickle', 'wb') as f:\n",
    "#     pickle.dump(model_ols_prophet, f)\n",
    "# pred_ols_prophet = model_ols_prophet.predict(steps_ahead=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ahp_arima = hts.HTSRegressor(model='auto_arima', revision_method='AHP', n_jobs=4)\n",
    "model_ahp_arima = model_ahp_arima.fit(hierarchy_df, hierarchy)\n",
    "with open('model_ahp_arima.pickle', 'wb') as f:\n",
    "    pickle.dump(model_ahp_arima, f)\n",
    "pred_ahp_arima = model_ahp_arima.predict(steps_ahead=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take last row of pred_ahp_prophet and convert it to a dataframe by making it into a column\n",
    "pred_ahp_prophet = pred_ahp_prophet.iloc[-1].to_frame().T\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5adb9b23f0db5198ad49ebc7528f71124eca3166c02a87711bfeed9aa94960d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
